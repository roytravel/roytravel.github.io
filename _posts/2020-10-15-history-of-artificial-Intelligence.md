---
date: 2020-10-15
layout: post
title: 인공지능의 역사
subtitle: 인공지능은 어떻게 발전해 왔는가
description:
  
image: /assets/img/history_of_ai.jpg
optimized_image:
  
category: ai
tags:
  - Artificial Intelligence
  - History
  - AI History
  - History of AI
  
  
author: Roytravel
paginate: true
---

이전 포스팅 : <a href="https://roytravel.github.io/brain-science-memory/">기억의 뇌과학(2)</a>

# 목차
* 인공지능의 개념
* 최초의 계산 시스템
* 인공지능의 역사
* 앨런튜링 - 인공지능의 개념적 토대를 놓다
* 다트머스 컨퍼런스
* 기호주의와 연결주의
* 첫 번째 AI 겨울과 AI의 부활
* 두 번째 AI 겨울과 AI의 부활


## 인공지능의 개념
![alt text](/assets/img/Artificial_Intelligence_2.jpg)

인공지능은 인간의 학습능력, 추론능력, 지각능력, 자연언어의 이해능력 등을 포함하는, 지능을 갖춘 컴퓨터 프로그램을 의미한다[1]. 이러한 인공지능의 목표로는 연산속도가 빠른 컴퓨터에 인간의 지능을 부여함으로써 효율적인 문제 해결을 도모하기 위함이다. 이러한 인공지능에 대해 이후에 언급될 지능과 생각 등이 무엇인가에 대한 튜링 테스트나 중국어 방 사고실험과 같은 철학적 관점의 문제가 제기되기도 한다.

## 최초의 계산 시스템
![VuePress 이미지](/assets/img/pascaline.jpg)*Pascaline*
최초의 계산기라 불리는 시스템은 1642년에 파스칼이라는 학자가 고안한 것으로, 파스칼린이라는 이름의 계산기로 세금계산서에 나오는 덧셈과 뺄셈을 위해 만들어졌다. 이후 1672년경에 철학자인 라이츠니츠가 곱셈을 처리할 수 있는 계산기를 고안했고 1694년에 Stepped reckoner라는 이름으로 완성되었는데, 이러한 라이프니츠의 업적은 0과 1 혹은 On과 Off로 표시할 수 있는 이진법을 개발해 현대식 컴퓨터(디지털) 개발에 초석을 놓았다는점에 의미가 있다. 이후 1822년 찰스 배비지는 조금 더 현대적인 의미의 컴퓨터를 고안하였고, "차분기관"이라하여 명령들을 해석하며 계산을 실행하는 기계 즉, 프로그래밍 가능한 컴퓨터를 설계하고 제작을 시도하였다.
![VuePress 이미지](/assets/img/stepped_reckoner.jpg)*Stepped reckoner*

## 인공지능의 역사

1943년 논리학자인 윌터 피츠와 신경과학자인 워렌 맥컬럭이 "A Logical Calculus of Ideas Immanent In Nervous Activity"라는 논문에서 인간의 사고 메커니즘에 해당하는 뉴런의 작용을 0과 1로 이루어지는 이진법 논리 모델로 설명하였고 1946년 범용 컴퓨터인 '에니악(ENIAC)'의 등장 이후부터 컴퓨터 연구와 함께 인공지능에 대한 연구가 진행되었다.


### 앨런튜링 - 인공지능의 개념적 토대를 놓다
![alt text](/assets/img/alan_turing.jpg)
이후 1950년 영국의 수학자인 앨런 튜링은 "Computing Machinery and Intelligence"라는 논문을 발표하였는데, 해당 논문은 생각하는 기계의 구현 가능성에 대한 것으로 "기계가 생각할 수 있는가?"라는 물음을 통해 그 유명한 튜링 테스트가 고안되었고 또한 인공지능에 대한 개념적 토대를 놓게 되었다.

### 다트머스 컨퍼런스
![alt text](/assets/img/Dartmouth_Conference.jpg)
1940년대와 1950년대에 이르러 다양한 영역의 과학으로부터 인공적인 두뇌의 가능성이 논의되었고, 1956년에 마빈 민스키와 존 매카시 등이 개최한 다트머스 컨퍼런스를 통해 현재 AI라 불리는 용어가 정립 되었으며 AI가 학문의 분야로 들어오는 계기가 되었다. 이 컨퍼런스에서 참석자들은 튜링의 '생각하는 기계'를 구체화하고 논리와 형식을 갖춘 시스템으로 이행시키는 방법을 두달간 논의하였다. 다트머스 컨퍼런스 이후 AI라는 새로운 학문은 대수학 문제를 풀고, 기하학의 정리를 증명하고, 영어를 학습 등의 발전의 땅을 질주하게 되었다. 



### 기호주의와 연결주의
이렇게 인공지능에 대한 개념적 토대를 놓은 1950년대의 인공지능 연구는 크게 두 분야인 기호주의와 연결주의로 나뉘었다. 기호주의는 인간의 지능과 지식을 기호화, 메뉴얼화하고 이를 따르는 컴퓨터가 있으면 문제 해결이 가능하다는 전제를 기반으로 하며, 이와 관련한 문제로는 체스, 미로, 퍼즐 등이 있다. 이러한 기호주의의 특징은 논리로 해결할 수 있는 문제, 메뉴얼화가 가능한 분야에 강하다는 장점이 존재하며, 영상인식이나 음성인식과 같은 논리로 설명하기 어려운 문제에 약하다는 단점이 있다. 기호주의의 성과로는 수학, 퍼즐, 체스, 미로등과 같은 논리적인 문제를 해결할 수 있게 되었으며 인간과 대화할 수 있는 챗봇이 탄생하게 되었다. 

이렇게 현실적으로 실현 가능하고 인공지능 기술의 기초가 되는 접근법인 기호주의 분야가 사람들의 관심을 받고 있었으나 1958년 프랭크 로젠블랫이 인공신경망(ANN)의 기본이 되는 알고리즘인 퍼셉트론(Perceptron)을 고안하게 되었고, 사람들의 사진을 대상으로 남자/여자를 구별해내게 되면서 뉴욕 타임즈에 실리게 되었고 이후 인공지능 연구의 트렌드가 기호주의에서 연결주의로 넘어오게 되는 계기가 되었다. 

연결주의의 경우 뇌 신경 네트워크의 재현을 목표로 하는 접근법으로, 인공지능 학습에 있어 좋은 경험(정보)가 있으면 문제를 해결할 수 있다는 전제를 기반으로 한다. 인간 또한 어떠한 방법을 통해 생각 하는지 알지 못하기에 말로 설명할 수 없는 문제의 경우 경험으로 배우는 것이 효과적이라는 것으로 현재의 기계학습으로 연결된다. 이러한 연결주의의 특징으로는 인간이 메뉴얼로 만들 수 없는 복잡한 문제여도 인공지능이 스스로 답을 찾을 수 있다는 점이다. 이러한 연결주의의 성과를 통해 앞서 언급한 퍼셉트론이 탄생하게 되었다.

기존의 기호주의를 이끌던 마빈 민스키는 연결주의에 비판적인 시각으로 1969년 『퍼셉트론』이라는 책을 출간하면서 기존의 연결주의의 한계 즉, 퍼셉트론의 한계를 수학적으로 증명하게 된다. 퍼셉트론의 경우 XOR 연산이 근본적으로 불가능한 모델이며, 실생활 적용에 있어 한정적이라는 사실을 비판하게 되면서 연결주의에 투자되어 있던 자금이 빠지기 시작하고, 1971년 로젠 블랫의 사망, P-NP 문제와 같은 기호주의의 한계를 다루는 논문이 인공지능이 조합의 증가(Combinational Explosion)을 다룰 수 없다고 발표되면서 소위 AI Winter라 불리는 시기가 15년동안 지속되는 계기가 되었다.

### 첫 번째 AI 겨울과 AI의 부활
![alt text](/assets/img/perceptron_for_logical_circuit.png)
마빈 민스키에 의해 퍼셉트론은 AND, OR, NAND와 같은 선형문제는 해결할 수 있으나, XOR과 같은 비선형 문제는 선형분리가 불가능하다는 한계로 인해 도래했던 첫 번째 AI 겨울은, 1986년 현재 딥러닝의 아버지라 불리는 제프리 힌튼 교수가 다층 퍼셉트론(Multi-Layer Perceptron)과 역전파(Backpropagation) 알고리즘을 제시하면서 기존의 XOR의 한계를 극복할 수 있는 것을 실험적으로 증명하게 되면서 AI가 부활하게 되었다.

정확히는, 1974년 하버드대의 Paul Werbos가 퍼셉트론 환경에서의 학습을 가능하게 하는 역전파 알고리즘을 고안하였고 인공지능에 대한 침체한 분위기 속 8년 후인 1982년 논문이 발표되었다. 또한 1982년 물리학자인 John Hopfield는 완벽히 새로운 경로에서 정보를 처리하고 학습할 수 있는 신경망의 형태를 증명하였고, 이 시기에 David Rumelhar는(Paul Werbos에 의해 발견된) 역전파라 불리는 신경망을 개선하기 위한 새로운 방법을 알리고 있었다. 이후 역전파 알고리즘과 다층 퍼셉트론은 1984년 얀 르쿤에 의해 다시 세상 밖으로 나오게 되었고, 병렬처리 형태로부터 영감을 받아 1986년 제프리 힌튼에 의해 세상에 알려지게 되었다.

### 두 번째 AI 겨울과 AI의 부활
다층 퍼셉트론과 역전파 알고리즘을 기반으로 1990년대 초반까지 문자 인식 및 음성 인식과 같은 프로그램의 구동 엔진으로 사용되면서 인공지능 연구에 발전을 이루었으나 Vanishing Graidnet(그래디언트 소실)과 Overfitting(과적합) 문제, 컴퓨팅 파워와 같은 한계점이 발견되면서 AI의 두 번째 겨울을 맞이하게 되었다. 하지만 꿋꿋히 인공신경망을 연구해오던 제프리 힌튼 교수는 2006년 "A fast learning algorithm for deep belief nets"라는 논문을 통해 신경망의 가중치의 초기값을 잘 설정한다면 DNN(Deep Neural Network)을 통한 학습이 가능하다는 것을 밝혀내면서 본격적으로 딥러닝이라는 용어가 사용되기 시작했으며, 2012년 제프리 힌튼 팀이 ILSVRC(ImageNet Large Scale Visual Recognition Challenge)라는 이미지 인식 경진대회에서 AlexNet라는 모델을 통해 당시 매우 힘든일이라 판단되었던 오류율을 큰 폭으로 낮추게 되면서 압도적인 우승을 차지했고 이후 다시금 AI의 부흥기가 시작 되었다.

### Reference
[1] <a href="https://ko.wikipedia.org/wiki/인공지능">https://ko.wikipedia.org/wiki/인공지능</a><br>
[2] <a href="https://brunch.co.kr/@storypop/28">https://brunch.co.kr/@storypop/28</a><br>
[3] <a href="https://insilicogen.com/blog/340">https://insilicogen.com/blog/340</a><br>
[4] <a href="https://pgr21.com/freedom/57391">https://pgr21.com/freedom/57391</a><br>
[5] <a href="https://www.youtobia.com/book/pages/the-history-of-artificial-intelligence-artifi-1258568592">Logo<a><br>

